from fastapi import APIRouter, HTTPException
from pydantic import BaseModel
from typing import List, Optional
from datetime import datetime, timedelta
from collections import Counter
import os
from supabase import create_client, Client
from dotenv import load_dotenv

load_dotenv()

router = APIRouter(prefix="/api/stats", tags=["search_stats"])

# Supabase í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY")

print(f"ğŸ” Supabase URL: {SUPABASE_URL[:30]}..." if SUPABASE_URL else "âŒ SUPABASE_URL not set")
print(f"ğŸ” Supabase Key: {'âœ… Set' if SUPABASE_KEY else 'âŒ Not set'}")

supabase: Client = None
if SUPABASE_URL and SUPABASE_KEY:
    try:
        supabase = create_client(SUPABASE_URL, SUPABASE_KEY)
        print("âœ… Supabase client initialized successfully")
    except Exception as e:
        print(f"âŒ Failed to initialize Supabase: {str(e)}")
else:
    print("âš ï¸ Warning: SUPABASE_URL or SUPABASE_KEY not set. Stats features will be limited.")

class SearchLog(BaseModel):
    keyword: str
    timestamp: str
    
class KeywordStat(BaseModel):
    keyword: str
    count: int
    
class TrendData(BaseModel):
    date: str
    count: int

@router.post("/search")
async def log_search(keyword: str):
    """
    ê²€ìƒ‰ í‚¤ì›Œë“œë¥¼ Supabaseì— ê¸°ë¡í•©ë‹ˆë‹¤.
    í‚¤ì›Œë“œê°€ ì´ë¯¸ ì¡´ì¬í•˜ë©´ countë¥¼ ì¦ê°€ì‹œí‚¤ê³ , ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤.
    PostgreSQL í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì›ìì ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    """
    print(f"ğŸ” Attempting to log search keyword: {keyword}")
    
    if not supabase:
        print("âŒ Supabase client not initialized")
        return {"status": "error", "message": "Database not configured"}
    
    try:
        print(f"ğŸ“¤ Calling Supabase RPC function...")
        # PostgreSQL í•¨ìˆ˜ í˜¸ì¶œ
        result = supabase.rpc('increment_search_keyword', {
            'search_keyword': keyword
        }).execute()
        
        print(f"âœ… Search logged successfully: {result.data}")
        return {"status": "success", "keyword": keyword, "data": result.data}
    except Exception as e:
        # ì—ëŸ¬ê°€ ë°œìƒí•´ë„ ê²€ìƒ‰ ê¸°ëŠ¥ì—ëŠ” ì˜í–¥ ì—†ë„ë¡ 200 ë°˜í™˜
        print(f"âŒ Search log error: {str(e)}")
        import traceback
        traceback.print_exc()
        return {"status": "error", "keyword": keyword, "message": str(e)}

@router.get("/popular-keywords")
async def get_popular_keywords(limit: int = 10) -> List[KeywordStat]:
    """
    ì¸ê¸° ê²€ìƒ‰ í‚¤ì›Œë“œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    if not supabase:
        return []
    
    try:
        # count ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
        response = supabase.table("search_log")\
            .select("keyword, count")\
            .order("count", desc=True)\
            .limit(limit)\
            .execute()
        
        popular = [
            KeywordStat(keyword=row['keyword'], count=row['count'])
            for row in response.data
        ]
        
        return popular
    except Exception as e:
        print(f"Error fetching popular keywords: {str(e)}")
        return []

@router.get("/search-trend")
async def get_search_trend(days: int = 7) -> List[TrendData]:
    """
    ê²€ìƒ‰ëŸ‰ ì¶”ì´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    ë‚ ì§œë³„ ì´ ê²€ìƒ‰ íšŸìˆ˜(count í•©ê³„)ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    if not supabase:
        return []
    
    try:
        # ëª¨ë“  í‚¤ì›Œë“œì˜ updated_atê³¼ count ê°€ì ¸ì˜¤ê¸°
        response = supabase.table("search_log")\
            .select("updated_at, count")\
            .execute()
        
        # ë‚ ì§œë³„ ê²€ìƒ‰ ìˆ˜ ì§‘ê³„ (updated_at ê¸°ì¤€)
        date_counts = Counter()
        for row in response.data:
            try:
                # updated_atì„ ë‚ ì§œë¡œ ë³€í™˜
                date = datetime.fromisoformat(row['updated_at'].replace('Z', '+00:00')).strftime('%Y-%m-%d')
                # í•´ë‹¹ ë‚ ì§œì˜ ì´ ê²€ìƒ‰ ìˆ˜ ëˆ„ì 
                date_counts[date] += row['count']
            except:
                pass
        
        # ë‚ ì§œë³„ ë°ì´í„° ìƒì„± (ë¹ˆ ë‚ ì§œë„ í¬í•¨)
        trend_data = []
        for i in range(days):
            date = (datetime.now() - timedelta(days=days-1-i)).strftime('%Y-%m-%d')
            count = date_counts.get(date, 0)
            trend_data.append(TrendData(date=date, count=count))
        
        return trend_data
    except Exception as e:
        print(f"Error fetching search trend: {str(e)}")
        import traceback
        traceback.print_exc()
        return []

@router.get("/keyword-relations")
async def get_keyword_relations(keyword: str, limit: int = 20):
    """
    ì—°ê´€ í‚¤ì›Œë“œë¥¼ count ìˆœìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    if not supabase:
        return []
    
    try:
        # ìš”ì²­í•œ í‚¤ì›Œë“œ ì œì™¸í•˜ê³  count ìˆœìœ¼ë¡œ ì •ë ¬
        response = supabase.table("search_log")\
            .select("keyword, count")\
            .neq("keyword", keyword)\
            .order("count", desc=True)\
            .limit(limit)\
            .execute()
        
        relations = [
            {"keyword": row['keyword'], "count": row['count']}
            for row in response.data
        ]
        
        return relations
    except Exception as e:
        print(f"Error fetching keyword relations: {str(e)}")
        return []
